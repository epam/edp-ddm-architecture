:toc-title: ЗМІСТ
:toc: auto
:toclevels: 5
:experimental:
:important-caption:     ВАЖЛИВО
:note-caption:          ПРИМІТКА
:tip-caption:           ПІДКАЗКА
:warning-caption:       ПОПЕРЕДЖЕННЯ
:caution-caption:       УВАГА
:example-caption:           Приклад
:figure-caption:            Зображення
:table-caption:             Таблиця
:appendix-caption:          Додаток
:sectnums:
:sectnumlevels: 5
:sectanchors:
:sectlinks:
:partnums:

= Видалення документів з S3 Ceph-бакетів

Для видалення документів для завершених бізнес-процесів, потрібно виконати наступні кроки:

. У поді `operational-instance` реєстру увійдіть до бази `camunda` та виконайте наступний SQL-скрипт:
+
[source,sql]
----
psql
\c camunda

COPY (select ae.id_ "process-instance-id", arv.text_ "start-form-document-key"  from act_ru_execution ae left join act_ru_variable arv on ae.id_ = arv.proc_inst_id_ and arv.name_ = 'start_form_ceph_key' where ae.parent_id_ is null) TO '/tmp/process_instance_ids.csv' csv header;
----

. Згенерований файл _/tmp/process_instance_ids.csv_ скопіюйте на локальну машину:
+
[source,kubectl]
----
kubectl cp --retries=-1 <citus-pod-name>:/tmp/process_instance_ids.csv ./process_instance_ids.csv
----

. (_Опціонально_) Встановіть `openjdk`.
. Далі відбувається робота з утилітою.
+
Звантажте останню збірку утиліти з Nexus за посиланням:
+
https://nexus-public-mdtu-ddm-edp-cicd.apps.cicd2.mdtu-ddm.projects.epam.com/nexus/#browse/search=keyword%3Dstorage-cleanup-cli[].
+
Запустити утиліту можна так:
+
----
java -jar storage-cleanup-cli.jar \
--running-processes-csv-file=<arg> \
--dry-run=<arg> \
--s3-ceph-url=<arg> \
--lowcode-file-storage-secret-key=<arg> \
--lowcode-file-storage-access-key=<arg> \
--ceph-removal-output-csv-file=<arg> \
--redis-url=<arg> \
--redis-secret=<arg> \
--redis-removal-output-csv-file=<arg> \
--removal-batch-size=<arg> \
--remove-only=<arg>

--lowcode-form-data-storage-secret-key=<arg>  Secret key for lowcode-form-data-storage bucket <optional> \
--lowcode-form-data-storage-access-key=<arg>  Access key for lowcode-form-data-storage bucket <optional>
----
+
Опис параметрів:

* `--running-processes-csv-file=<arg>` -- шлях до згенерованого CSV-файлу.
* `--dry-run=<arg>` -- `true` або `false`, атрибут, що індикує, чи буде видалення зі сховища. При `true` - згенерується файл на видалення, але не відбудеться видалення. Значення за замовчуванням -- `false`.
* `--s3-ceph-url=<arg>` -- URL сховища, як-от `"http://s3-ceph-openshift-storage.apps.reestr1.eua.gov.ua/"`.
* -`-lowcode-file-storage-secret-key=<arg>` та `--lowcode-file-storage-access-key=<arg>` -- секрет та ключ доступу до бакета `lowcode-file-storage` (в Openshift шлях такий: *Workloads* > *Secrets* > *`lowcode-file-storage`*).
* `--ceph-removal-output-csv-file=<arg>` -- файл на видалення для CEPH.
* `--redis-url=<arg>` -- посилання до `redis` (_так як немає прямого роута, нижче див. інструкція з переадресації портів для_ `redis`).
* `--redis-secret=<arg>` -- пароль до redis із секрету `redis-auth` реєстру.
* `--redis-removal-output-csv-file=<arg>` -- файл на видалення для `redis`.
* `--removal-batch-size=<arg>` -- batch-розмір для видалення (за замовчуванням -- 1000).
* `--remove-only=<arg>` -- `true`, якщо це лише видалення, якщо `false` -- зчитування файлів на видалення і видалення; ключі на видалення беруться з `ceph-removal-output-csv-file`.

[TIP]
====

* Переадресація портів для поду redis: xref:registry-admin/cleanup-redis-abandoned-processes.adoc[]

* Визначити розмір бакетів можна через CEPH Dashboard: xref:registry-admin/define-ceph-buckets-space.adoc[]
====

////

НЕ ТЕСТУВАЛОСЯ

----
#!/bin/bash

S3_ENDPOINT="http://s3-ceph-openshift-storage.apps.reestr1.eua.gov.ua"
BUCKETS=$(oc -n "$1" get objectbucketclaim --no-headers -o custom-columns=":metadata.name")

for bucket in $BUCKETS ; do
  echo "Querying $bucket ..."
  AWS_ACCESS_KEY_ID=$(oc -n "$1" get secret "$bucket" --template={{.data.AWS_ACCESS_KEY_ID}} | base64 --decode)
  AWS_SECRET_ACCESS_KEY=$(oc -n "$1" get secret "$bucket" --template={{.data.AWS_SECRET_ACCESS_KEY}} | base64 --decode)
  aws configure set aws_access_key_id "$AWS_ACCESS_KEY_ID" --profile "profile-$bucket" && aws configure set aws_secret_access_key "$AWS_SECRET_ACCESS_KEY" --profile "profile-$bucket"
  aws --profile "profile-$bucket" --endpoint="$S3_ENDPOINT" s3 ls | cut -d' ' -f3- | xargs -I {} aws --profile "profile-$bucket" --endpoint="$S3_ENDPOINT" s3 ls --summarize --human-readable --recursive s3://{}/ | grep -A2 -B2 "Total Size"
  printf "%60s" " " | tr ' ' '-' && printf "\n"
done
----

image:registry-admin/delete-docs-s3-ceph-buckets/delete-docs-s3-ceph-buckets-1.png[]
////