:toc-title: ЗМІСТ
:toc: auto
:toclevels: 5
:experimental:
:important-caption:     ВАЖЛИВО
:note-caption:          ПРИМІТКА
:tip-caption:           ПІДКАЗКА
:warning-caption:       ПОПЕРЕДЖЕННЯ
:caution-caption:       УВАГА
:example-caption:           Приклад
:figure-caption:            Зображення
:table-caption:             Таблиця
:appendix-caption:          Додаток
:sectnums:
:sectnumlevels: 5
:sectanchors:
:sectlinks:
:partnums:

= Міграція реєстрів

== Позначення та скорочення

* [.underline]#Кластер А# -- кластер, на якому розгорнуто наявний реєстр.
* [.underline]#Кластер B# -- кластер, куди буде перенесено наявний реєстр (цільовий кластер).

NOTE: Міграція реєстру виконується з останньої резервної копії наявного реєстру та, відповідно до інструкції, буде переноситися із кластера А до кластера B й відновлюватися вже на цьому кластері.

== Передумови для міграції

. Користувач, який буде переносити реєстр на інший кластер, повинен бути доданий в адміністратори платформи на обох кластерах через *`control-plane-console`*.
+
TIP: Див. детальніше -- xref:admin:registry-management/control-plane-assign-platform-admins.adoc#add-platform-admin-cp[Створення адміністратора платформи].
. На кластері, на який переноситься реєстр, повинна бути розгорнута та версія платформи, у якої версія `control-plane-gerrit` буде дорівнювати версії самого реєстру (наприклад, версія платформи -- *`1.9.4.11`*, версія реєстру -- *`1.9.4.7`*, версія `control-plane-gerrit` – *`1.9.4.7`*). Цю версію можна перевірити наявністю гілки у репозиторії *`cluster-mgmt`* в центральному *Gerrit*. Якщо гілка з версією реєстру існує, то версію реєстру можна переносити на кластер B. Якщо ні, то існує два шляхи:

* Оновити платформу на кластері B, яка буде відповідати версії самого реєстру.
* Оновити реєстр на кластері A до версії, яка вже існує на кластері B.

. Одночасний доступ до кластера А та кластера B.

. Наявність наступних команд в Terminal:

* `oc`
* `velero`
* `rclone`
* `vault`

. Стабільне з'єднання з інтернетом. _Чим більша пропускна здатність, тим швидше буде проходити міграція_. В іншому випадку, можна використовувати *jumpbox* (із доступом до обох кластерів), який знаходиться або в AWS, або в іншого cloud-провайдера. Використання jumpbox зменшить час перенесення резервної копії з одного кластера на інший.
+
[NOTE]
====
Якщо ви використовуєте *jumpbox*, то необхідно перевірити доступ до платформних Minio/Vault із IP-адреси *jumpbox*. Для отримання IP *jumpbox* виконайте наступну команду:
----
ssh sshmyip.com
----

Далі необхідно перевірити наявність IP адреси в annotations за шляхом: *Openshift*-консоль > *Project* -> *control-plane* > *Networking* > *Routes* -> *`platform-minio`* aбо *`platform-vault`* > *YAML*:
----
  annotations:
    haproxy.router.openshift.io/ip_whitelist: <IP jumpbox>/32,....
----
Якщо відсутні ресурси в Openshift Console, зверніться до L2-команди для перевірки доступу.
====

== Підготовка реєстру до міграції

. Зробіть резервну копію реєстру на кластері A.
+
Перед перенесенням реєстру на новий кластер, необхідно запустити Jenkins-процес *`Create-registry-backup-<назва реєстру>`*.
+
Якщо Jenkins pipeline завершився зі статусом *`Success`*, то резервна копія виконана успішно.
+
[NOTE]
====
Для отримання назви резервної копії, перейдіть до логів/журналів подій останнього запуску Jenkins pipeline (*Console Output*), та за пошуком на сторінці знайдіть повідомлення накшталт:

----
[INFO] Velero backup - <назва реєстру>-<час> done with Completed status
----

Наприклад, таке:

----
[INFO] Velero backup - abc-02-2023-04-18-19-03-14 done with Completed status
----

* де *`abc-02-2023-04-18-19-03-14`* -- назва резервної копії.

====
+
[WARNING]
====
Для версій реєстру < 1.9.3 необхідно виконати у Terminal наступну команду:

----
velero backup describe <назва бекапу>
----

Назву бекапу можна знайти в логах останнього запуску Jenkins-процесу *`Create-registry-backup-<назва реєстру>`*.
====
+
[TIP]
====
Детальніше про створення резервних копій та відновлення реєстрів див. у розділі xref:backup-restore/overview.adoc[].
====

. Якщо останній velero backup завершився зі статусом *`Completed`*, то можна переходити далі. У випадку, коли статус velero backup відрізняється від `Completed`, необхідно долучати спеціалістів із технічної підтримки L2-L3 для перевірки працездатності Jenkins-пайплайну.

. Забороніть робити зміни у реєстрі за допомогою Jenkins пайплайнів.
+
У кожному пайплайні для реєстру перейдіть до секції *Configure* та знайдіть параметр *`Disable this project`* у секції *Build Triggers*, встановіть напроти нього прапорець та збережіть зміни за допомогою кнопки kbd:[*Save*].

== Міграція резервної копії із кластера А до кластера B

. Отримайте логін-команди для обох кластерів.
+
Для цього виконайте вхід до Openshift-консолі та у правому верхньому кутку, натисканням на свій username, перейдіть до *`Copy login command`*, скопіюйте токен доступу у полі *`Log in with token`* та збережіть його у текстовому редакторі.

+
NOTE: Операцію потрібно повторити для обох кластерів: А та B.

. Отримайте назву останньої резервної копії, яка була створена на кластері А (наприклад, `abc-02-2023-04-18-19-03-14`).

. Відкрийте термінал та виконайте наступні команди:
+
.Експорт логіну для кластера А
----
export A_CLUSTER_LOGIN="oc login --token …"
----
+
Вставте між лапок *`"..."`* після `--token` отриману в пункті 1 команду логіну для кластера А. В кінці логін-команди не повинно бути перенесення на наступний рядок.

+
.Експорт логіну для кластера В
----
export B_CLUSTER_LOGIN="oc login --token …"
----
+
Вставте між лапок *`"..."`* після `--token` отриману в пункті 1 команду логіну для кластера В. В кінці логін-команди не повинно бути перенесення на наступний рядок.

+
.Експорт назви реєстру
----
export REGISTRY_NAME="<назва реєстру>"
----
+
TIP: Приклад назви реєстру: `*abc-02*`.

+
.Експорт назви резервної копії
----
export BACKUP_NAME="<назва резервної копії>"
----
+
TIP: Приклад назви резервної копії: `*abc-02-2023-04-18-19-03-14*`.

. Збережіть link:{attachmentsdir}/migrate-registry/registry-migration.zip[архів], розархівуйте його в нову директорію наступною командою:
+
----
unzip registry-migration.zip -d registry-migration
----
+
Перейдіть в директорію registry-migration (`cd`) та виконайте команду:
+
----
chmod +x && ./migration.sh
----

. Після виконання скрипту, виконайте логін у терміналі за допомогою *oc cli* на кластері B, та перевірте наступне:

* Наявність velero backup на кластері B.
* Наявність директорій із назвою _keycloak-export-<назва реєстру>-*_ у папці, де знаходиться скрипт.

== Підготовка до відновлення на кластері B

. Перенесіть реалми.
+
Для перенесення реалмів, виконайте вхід до Keycloak на кластері B:

* В Openshift-консолі знайдіть проєкт (namespace) *`user-management`*, відкрийте *Networking* > *Routes* та перейдіть за посиланням до сервісу *`keycloak`*.
+
TIP: Дані для логіну можна отримати із секретів keycloak у тому ж проєкті. Для цього перейдіть до Workloads > Secrets, знайдіть у пошуку секрет із назвою *`keycloak`*, та у розділі Data скопіюйте дані для входу до сервісу.

* За допомогою `*Select realm*` (1) > *`Add realm`* (2) > *`Import`* (3), виберіть файл _keycloak-export-<назва реєстру>-*/*-realm.json_ та створити реалми (оберіть стратегію *`SKIP`*, запропоновану Keycloak). Так пройдіться по усіх директоріях із назвою _keycloak-export-<назва реєстру>-*_.

+
image:admin:migrate-registry/migrate-registry-1.png[image,width=514,height=194]

. Перенесіть користувачів.
+
Залишаючись в адмін-консолі Keycloak, перейдіть до реалму (1), який був створений за допомогою імпорту, та у лівому меню реалму оберіть  *`Import`* (2) (при імпорті оберіть стратегію *`SKIP`*), далі натисніть *`Select file`* (3) та виберіть файл із директорії _keycloak-export-<назва реєстру>-<ім’я реалму>/<ім’я реалму>-users-*.json_.
+
NOTE: Якщо файлів більше одного, то виконайте імпорт усіх файлів.

+
image:admin:migrate-registry/migrate-registry-2.png[image,width=601,height=417]

. Створіть реєстр через *`control-plane-console`*.

* Створіть реєстр з тим же ім'ям, і такою ж версією на кластері B. При створенні реєстру призначте усіх адміністраторів, що були у реєстрі на кластері A, та вкажіть актуальні дані.
+
[NOTE]
====
Дані про ключ ::
Поля заповніть або з актуальними ключами для цього реєстру, або використовуйте тестові ключі. У майбутньому, після міграції, інформацію про ключі можна актуалізувати через консоль *Control Plane*. За даними для ключів звертатись до L2-L3 підтримки.
+
Детальніше про оновлення ключів реєстру -- див. на сторінці xref:admin:registry-management/system-keys/control-plane-registry-keys.adoc[].

Шаблон реєстру ::
Оберіть такий самий шаблон, як і шаблон цього реєстру на кластері A. Для отримання назви шаблону, перейдіть до *Openshift*-консолі > *Projects* > *`control-plane`* > *API Explorer* > У пошуку визначте `codebase` > Перейдіть до `codebase` > *Instances* > Відкрийте `codebase <назва реєстру>` > Перевірте наступні налаштування:
+
.codebase.yaml
=====
----
metadata:
  annotations:
    registry-parameters/template-name: templates/registry-tenant-template-minimal
----
* де *`templates/registry-tenant-template-minimal`* -- назва шаблону розгортання реєстру.
=====
====
+
NOTE: Якщо функціональність консолі дозволяє додати DNS для keycloak або порталів, на цьому етапі необхідно пропустити цей крок, адже трафік поки налаштований на кластер A).

* Після створення, одразу перейдіть до Jenkins (namespace *`control-plane`* > *Networking* > *Routes* > *`jenkins`*), та зупиніть першу збірку *`MASTER-Build-<назва реєстру>`*.
+
NOTE: Треба дочекатись створення директорії <назва реєстру> та створення Jenkins pipeline, після запуску одразу зробити Abort білда.

. Перевірка наявності `*CustomResourceDefintition*`.
+
[WARNING]
====
Якщо до цього на кластері не було жодного реєстру, обов'язково перевірте наявність існування *`CustomResourceDefintition`*. Для цього виконайте логін через *`oc cli`* на кластері B та виконати наступну команду:

----
oc get customresourcedefinition ingressclassparameterses.configuration.konghq.com
----

Якщо команда завершиться з помилкою та видасть у консолі *`No resources found`*, то перейдіть до директорії, де знаходиться скрипт *_migration.sh_*, та з кореневого шляху виконайте наступну команду:

----
for file in $(ls crds); do oc apply -f crds/$file; done
----
====

== Відновлення реєстру на кластері B

. Відрийте до Jenkins (namespace *`control-plane`* > *Networking* > *Routes* > *`jenkins`*), перейдіть до папки із назвою реєстру та запустіть Jenkins-пайплайн *`Restore-registry-<назва реєстру>`*. Після запуску пайплайну оберіть версію( на етапі cleanup-registry-before-restore ) та дочекатися, коли процес завершиться.
+
NOTE: У випадку, коли процес завершується помилкою або триває понад 1-2 години, зверніться до спеціалістів команди технічної підтримки L2-L3 "ЕПАМ".

. Після завершення пайплайну перейдіть в Openshift-консоль > Projects > <назва реєстру>, та перевірте, що немає под у статусі помилок.
+
[NOTE]
====
У випадку, коли пода із назвою *`bpms-*`* не запущена і має статус помилки, виправте паролі у `postgres` для *`operational-instance`* та *`analytical-instance`* под, для цього потрібно:

* Перейдіть в *Openshift*-консоль > Secrets, знайдіть secret для `operational-instance` -- *`operational-pguser-postgres`* (для `analytical-instance` -- це *`analytical-pguser-postgres`*).
* Перейдіть в *Secret* та скопіюйте поле *`password`*.
* Перейдіть в *Openshift*-консоль > *Pods* > знайдіть поду *`operational-instance`* або *`analytical-instance`* та виконайте по черзі наступні команди:
+
[source,bash]
----
psql
----
+
[source,sql]
----
ALTER ROLE postgres WITH PASSWORD '<password>';
----

** де *`<password>`* -- поле `password`, скопійоване у *Secret* для відповідного екземпляра -- `operational` або `analytical`.

* Після виконання усіх операцій, видаліть поду *`bpms`* та дочекайтеся, коли вона буде у статусі *`Running`* (активна/запущена).
====
+
[NOTE]
====
У випадку, коли пода *`registry-rest-api`* запускається з помилкою `ImagePullBackOff`, додайте IP кластера B до анотації *Openshift Route* > *Nexus*.

* Для цього перейдіть в *Openshift*-консоль > *Project* > `<назва реєстру>` > *Routes* > *Nexus* > *YAML* та перевірте наступне поле у _.yaml_-конфігурації:.
+
.route.yaml
=====
----
metadata:
  annotations:
    haproxy.router.openshift.io/ip_whitelist: <NAT Cluster IP>/32,....
----
=====
+
Якщо IP-адреса кластера B відсутня, додайте її до *`haproxy.router.openshift.io/ip_whitelist`* із маскою *`/32`*.

====
+
. Після перевірки, що усі поди у статусі *`Running`*, перенесіть конфігурацію реєстру до *_values.yaml/values.gotmpl_*.
+
* Увійдіть до *_control-plane-gerrit_* (*Openshift*-консоль > *Projects* -> *`control-plane`* -> *Networking* -> *`gerrit`* > Логін через *`openshift-sso`*).
+
У Gerrit перейдіть до *Browse* > *Repositories* та оберіть репозиторій *`<назва реєстру>`*. Через *`commands`* > *`Create change`* створіть зміну (сhange) із наступними параметрами:

** `Select branch for new change: master`.
** `Description: Update registry after migration`.
+
Після створення change, у самому change натисніть *`Edit`*.

* Додайте конфігурацію `vault` у *_values.gotmpl_*.
+
Для цього візьміть актуальну конфігурацію `vault` з config-map *`hashicorp-vault-config`* (*Openshift*-консоль > *Projects* > `<назва реєстру>` > *Workloads* > *ConfigMaps* > *`hashicorp-vault-config`*) та скопіюйте поле як у наступному прикладі:
+
----
ui = true

listener "tcp" {
  tls_disable = 1
  address = "[::]:8200"
  cluster_address = "[::]:8201"
}
storage "file" {
  path = "/vault/data"
}
seal "transit" {
   address         = "https://<vault url>"
   disable_renewal = "false"
   key_name        = "<key name>"
   mount_path      = "transit/"
   tls_skip_verify = "true"
}
----
+
* де *`<vault URL>`* -- посилання до *`vault`*, *`<key name>`* -- назва ключа (у конфігурації з `config-map` будуть актуальні поля).
+
Далі в change натисніть *`ADD/OPEN/UPLOAD`*, у пошуку вкажіть *_values.gotmpl_* та виберіть потрібний файл. В самому файлі додайте конфігурацію як у прикладі:
+
[source,yaml]
----
vault:
  platformVaultToken: {{ env "platformVaultToken" }}
  openshiftApiUrl: {{ env "openshiftApiUrl" }}
  centralVaultUrl: {{ b64dec $centralVaultUrl }}
  server:
    dataStorage:
      storageClass: ocs-storagecluster-ceph-rbd
    auditStorage:
      storageClass: ocs-storagecluster-ceph-rbd

    standalone:
      config: |
       ui = true

       listener "tcp" {
         tls_disable = 1
         address = "[::]:8200"
         cluster_address = "[::]:8201"
       }
       storage "file" {
         path = "/vault/data"
       }
       seal "transit" {
          address         = "https://<vault url>"
          disable_renewal = "false"
          key_name        = "<key name>"
          mount_path      = "transit/"
          tls_skip_verify = "true"
       }
----

* Після додавання натисніть Save.

* Змініть розмір `kafka`-дисків. Залишаючись у цьому файлі, знайдіть поле:
+
[source,yaml]
----
storage:
  zookeeper:
    size: 5Gi
  kafka:
    size: 20Gi
----

* Змініть розмір `kafka.size` відповідно до розміру актуального диска в *Openshift*-консолі (*Openshift*-консоль > *Project* -> `<назва реєстру>` -> *Storage* > *`PersistentVolumeClaims`* ). У пошуку знайдіть *`data-0-kafka-cluster-kafka-0`* та його *`Capacity`*. Поверніться до редагування _values.gtmpl_ та встановіть бажаний розмір диска:
+
----
storage:
  zookeeper:
    size: 5Gi
  kafka:
    size: 40Gi
----

** де 40Gi - актуальний розмір диска з `Capacity`.

* Видаліть усіх *`GerritGroupMember`*. Для цього виконайте вхід до кластера B через ос cli та виконати наступну команду:
+
----
oc -n <назва-реєстру> delete gerritgroupmember --all
----

. Запустіть Jenkins-процес *`MASTER-Build-<назва реєстру>`*.
. Після з завершення Jenkins-пайплайну *`MASTER-Build-<назва реєстру>`*, виправте Jenkins Credentials у Jenkins реєстру.
+
[NOTE]
====
У випадку, коли доступу немає, додайте себе як адміністратора реєстру через control-plane-console.
====
* Для цього перейдіть в *Openshift-консоль* > *Projects* > `<назва реєстру>` > *Workloads* > *Secrets* > *`gerrit-control-plane-sshkey`* та скопіюйте поле *`id_rsa`*.

* Після цього перейдіть у реєстровий Jenkins (*Networking* > *Routes* > `*jenkins*`) > Manage Jenkins > Manage Credentials > *`gerrit-ci-users-sshkey`* (*`gerrit-control-plane-sshkey`*) > натисніть *`Update`*.

* У полі *`Private Key`* за допомогою *`Replace`* вставте скопійоване значення.

. Оновіть посилання на Nexus у репозиторії регламенту.
+
Для цього перейдіть до Openshift-консоль -> Project -> <назва реєстру> -> Gerrit, та виконайте логін.
+
Далі перевірте наявність доступу до проєктів у Gerrit та клонуйте локально репозиторій *_registry-regulations_*. Для цього:

* У вебінтерфейсі Gerrit, перейдіть у налаштування > *HTTP Credentials* > згенеруйте новий пароль за допомогою `*Generate New Password*`, та збережіть цей пароль у нотатках.

* Перейдіть до репозиторію *`registry-regulations`* > та скопіюйте команду  для клону *Anonymous HTTP* > *`Clone with commit-msg hook`*. +

* Вставте команду для клону репозиторія до термінала та виконайте. Команда запитає логін та пароль. Логін в цьому випаду буде ваш email, а пароль -- той, який ви згенерували у першому підпункті.
+
TIP: Детальніше про роботу з репозиторієм Gerrit див. на сторінці xref:registry-develop:registry-admin/regulations-deploy/registry-admin-deploy-regulation.adoc[].
+
[NOTE]
====
Якщо в системі git user відрізняється від вашого user на сервері Gerrit, виконайте наступні команди:
----
git config --global user.name "New Author Name"
git config --global user.email "<email@address.example>"
----

Наприклад:
----
git config --global user.name "Jonh Doe"
git config --global user.email "jong_doe@doemail.com"
----
====

. Змініть мінорну версію в _settings.yaml_ у кореневій (root) директорії репозиторію *_registry-regulations_* згідно із приладом:
+
----
settings:
  general:
    package: ua.gov.mdtu.ddm.dataplatform.template
    register: registry
    version: 2.21.0
----
Наприклад, додайте до версії `+1`:
+
----
settings:
  general:
    package: ua.gov.mdtu.ddm.dataplatform.template
    register: registry
    version: 2.21.1
----

. Замініть згадування DNS-кластера А на кластер B. Для цього у терміналі перейдіть до директорії *_registry-regulations/data-model_*
+
----
cd registry-regulations/data-model
----
Та виконайте наступну команду по заміні DNS:
+
----
find "." \( -type d -name .git -prune \) -o -type f -print0 | xargs -0 sed -i -e  's/<Cluster A DNS wildcard> /<Cluster B DNS Wildcard> /g'
----
+
[TIP]
====
`Cluster A DNS wildcard/Cluster B DNS wildcard` -- це *`apps.*`* (наприклад, `*apps.reestr1.eua.gov.ua*`).
Як повинно виглядати sed правило:
----
's/apps.cluster-a.dns.wildcard.com/apps.cluster-b.dns.wildcard.com/g'
----
====

. Виконайте commit змін та push до репозиторію:
+
[source,git]
----
git add .
----
+
[source,git]
----
git commit -m "Update nexus URL"
----
+
[source,git]
----
git push origin refs/heads/master:refs/for/master
----

. Перейдіть у реєстровий Gerrit, проставте відмітки *`Code-Review +2`*, та за допомогою кнопки kbd:[*Submit*] застосуйте зміни до master-гілки.

. Після внесення змін до master-гілки перейдіть до Jenkins реєстру та перевірте, що Jenkins-пайплайни у Jenkins Folder *registry-regulations* завершилися зі статусом *`Success`*.

== Перевірка реєстру

. Переконайтеся, що Кабінети користувачів працюють у штатному режимі, та бізнес-процеси мігрували успішно.

. Усі Jenkins pipeline мають завершитися зі статусом *`Success`*.

NOTE: У випадку будь-яких проблем із міграцією, зверніться до Anatolii_Stoliarov@epam.com.
