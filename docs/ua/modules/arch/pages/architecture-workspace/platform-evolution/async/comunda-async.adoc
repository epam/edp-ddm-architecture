= Асинхронне завантаження даних

== Загальний опис

В поточній імплементації існує механізм який дозволяє завантажити csv файл з даним які будуть завантажені до відповідної таблиці. Цей процес відбувається синхронно, тому відповідь клієнт має отримати за 30 секунд (максимальний допустимий таймаут). Окрім того оскільки комунікація між сервісами синхронного та асинхронного управління даними реєстру відбувається через брокер повідомлень, існує ліміт в один мегабайт для повідомлень. Тому було встановлено штучний ліміт в 50 рядків. В процесі експлуатації виникла необхідність завантажувати більші об'єми даних, за розміром завантаження яких може займати значно довший час.


== Функціональні сценарії

* Збереження даних з файлу який більше одного мегабайта і збереження якого може тривати довше ніж 30 секунд.
* Збереження даних з файлу у декілька таблиць.

== Ролі користувачів

* Розробник регламенту
* Надавач послуг

== Загальні принципи та положення

* Збереження даних з файлу відбуваються в одній транзакції.
* Опрацювання файлу відбувається по рядках.
* Бізнес процес будується на подіях які виникають при відправці повідомлення до брокера.
* Події завантаження в бізнес процес мають обробляться головним процесом і не можуть бути проасоційовані із саб-процесом.
* Операція збереження відбувається асинхронно.
* Прогрес завантаження не відслідковується.
* В якості посилання на похідний документ для всіх сутностей буде один ключ на весь файл без вказання на конкретний рядок.
* Фали що не відповідають правилам встановленим моделювальникам не можуть бути завантажені.
* Обмеження по розміру файлу керується на рівні control plane

== Високорівневий дизайн рішення

image:architecture-workspace/platform-evolution/async/context.svg[]

image:architecture-workspace/platform-evolution/async/context-details.svg[]


=== Ключові сценарії взаємодії сервісів

.Опрацювання файлу
[plantuml, req, svg]
----
!theme plain
participant "Кабінет" as portal
participant "Сервіс завантаження\n документів" as dds
box "BPMS" #LightBlue
participant "Бізнес процес" as bpms
participant "Kafka делегат " as delegate
participant "Kafka Listener" as listener
end box
participant "Registry Rest API" as restApi
queue "Kafka" as kafka
collections "Ceph" as ceph
participant "Registry Kafka API" as kafkaApi
database "Операційна\nбаза даних" as db
participant "Keycloak" as keycloak

== Збереження файлів ==
portal -> dds: завантаження файлу
dds -> restApi: валідація вмісту файлу по відношенню до структури та кількості сутностей
return структура та вміст валідні
dds -> ceph: збереження документу
return документ завантажено
dds --> portal: ключ ceph до документу
portal -> bpms: відправка форми з ключем файлу
group опційний крок
bpms -> bpms: перетворення csv файлу
bpms -> ceph: збереження результату обробки
return ключ
end
bpms -> delegate: формування запиту

== Завантаження даних ==
delegate -> kafka: повідомлення завантаження \n [вхідна черга повідомлень]
kafkaApi -> kafka: отримання запиту на збереження файлу
kafkaApi -> keycloak: отримання сертифікату для валідації токену
return публічний сертифікату
kafkaApi -> kafkaApi: валідація токену
kafkaApi -> ceph: завантаження файлу
return файл за данними
kafkaApi -> kafkaApi: валідація вмісту файлу по відношенню до\nструктури та кількості сутностей
kafkaApi -> ceph: збереження файлу в окреме сховище
return
group цикл [кожен рядок]
kafkaApi -> db: збереження відповідним сервісом
return результат збереження
end
kafkaApi -> kafkaApi: формування відповіді
kafkaApi --> kafka: повідомлення з результатом обробки \n [вихідна черга повідомлень]
listener -> kafka
listener -> listener: кореляція з запитом,\n формування події згідно зі статусом
listener -> bpms: формування події
bpms --> portal: результат опрацювання
----


== Моделювання регламенту реєстру

=== Розширення для моделювання

Для реалізації можливості асинхронного завантаження сутностей до БД, конфігурація складається з декілька частин:

Конфігурація на рівні моделі даних за допомогою розширення liquibase, моделювання форми по завантаженню файлів та використання делегату асинхронної взаємодії при моделюванні БП.

.Розширення бібліотеки liquibase
[source, xml]
----
<changeSet>
    <createTable name="item">
        <!-- Опис полів таблиці !-->
    </createTable>
    <createTable name="demo_entity">
        <!-- Опис полів таблиці !-->
    </createTable>

    <createCompositeEntity name="item_with_references">
        <!-- Опис полів складної сутності !-->
    </createCompositeEntity>

    <createAsyncLoad name="allowedAsyncLoads">
        <entityList>
            <entity name="item" limit="100"/>
            <entity name="item_with_references" limit="1000"/>
            <entity name="demo_entity" limit="1000000"/>
        </entityList>
    </createAsyncLoad>

    <deleteAsyncLoad name="removeEntities">
        <entityList>
            <entity name="demo_entity"/>
        </entityList>
    </deleteAsyncLoad>

</changeSet>
----
Атрибут `limit` є обовʼязковим при створенні `createAsyncLoad`

image:architecture-workspace/platform-evolution/async/business-process.png[]

.Конфігурація делегату для асинхронного завантаження
====
image:architecture-workspace/platform-evolution/async/delegateConfiguration.png[]
====
В результаті обробки, можливе виникнення декількох подій, в залежності від статусу результату.
Тип події складається з назви сутності та статусу.

.Приклади налаштування обробки подій успішного завантаження сутності item
====
image:architecture-workspace/platform-evolution/async/succesEvent.png[]
====

.Приклади налаштування обробки подій для при збереженні сутності item
====
image:architecture-workspace/platform-evolution/async/constraintViolation.png[]
====

Загальне правило для формування подій при асинхронній взаємодії формується за допомогою `camel case` і складається з `назви сутності над якою здійснюється операція + назва операція + результат операції`

.Можливі статуси результату опрацювання
|===
|Результат операції |Опис |Приклад події на бізнес процесі

|SUCCESS
|Операція  закінчилась успішно.
|%item%DataLoadCsvSuccess

|CONSTRAINT_VIOLATION
|Дані з файлу не можуть бути завантаженні оскільки один з них порушує існуючі правила БД.
|%item%DataLoadCsvConstraintViolation

|OPERATION_FAILED
|Під час опрацювання файлу виникла помилка.
|%item%DataLoadCsvOperationFailed
|===


== Низькорівневий дизайн сервісів

=== Бібліотека Liquibase-розширень для моделювання дата моделі реєстру

Результатом обробки тегів `createAsyncLoad` `deleteAsyncLoad` є формування переліку структур для яких дозволено асинхронне завантаження даних з файлів в таблиці метаданих.

=== Делегат для відправки асинхронних повідомлень

При відправці повідомлення за допомогою делегата, разом з тілом повідомлення відправляються службові заголовки для трасування.

.Приклад тіла повідомлення для збереження даних з файлу
[source,json]
----
{
  "requestContext": {
    "businessProcessInstanceId": "...",
    "businessProcessName": "...",
    "...": "..."
  },
  "securityContext": {
    "signature": "...",
    "jwtToken": "...",
    "...": "..."
  },
  "payload": {
    "resultVariable": "asyncDataLoadResult", // Змінна бізнес процесу в яку мають бути збережено результат
    "file": {
      "checksum": "....",
      "id": "process/bp-instance-id/uuid"
    },
    "derivedFile": {
      "checksum": "...",
      "id": "process/bp-instance-id/uuid"
    },
    "entityName": "item" // Назва сутності
  }
}
----

=== Сервіс синхронного управління даними реєстру
Валідація відбувається згідно існуючого процесу за рахунок проксювання запитів до сервісу синхронного управління даними, правила щодо дозволеної кількості сутностей виставлених моделювальником формується на етапі генерації сервісу.

=== Сервіс асинхронного управління даними реєстру

Процес обробки повідомлення здійснюється існуючими обробниками для збереження сутностей (`createEntity`, `createCompositeEntity`) який обирається динамічно по тупи сутності в залежності від значення поля `entityName`, формування переліку маршрутизації `entityName`  до обробника відбувається на етапі генерації.

Результатом обробки буде статус та деталі до повідомлення.

[source, json]
----
{
  "payload": {
    "resultVariable": "...",
    "requestContext": {
        "businessProcessInstanceId": "...",
        "businessProcessName": "...",
        "...": "..."
    }
  },
  "status": "SUCCESS",
  "details": "OK"
}
----

[source, json]
----
{
  "payload": {
    "resultVariable": "...",
    "requestContext": {
        "businessProcessInstanceId": "...",
        "businessProcessName": "...",
        "...": "..."
    }
  },
  "status": "CONSTRAINT_VIOLATION",
  "details": "error: {%s} in line: {%d}"
}
----

Текст з помилки про порушення правил БД, береться з процедури, а номер рядка за рахунок ведення лічильника в середині транзакції.


=== Обробник повідомлень подій результатів завантаження даних для сервісу виконання бізнес-процесів

Кореляція результату з бізнес процесом відбувається за рахунок `BusinessProcessInstanceId` з контексту.
А тип повідомлення формується динамічно на підставі типу сутності та результату.

.Приклад можливої кореляції
[source, java]
----
@Component
public class AsyncDataLoadResponseKafkaListener {
    private static final String ACTION = "DataLoadCsv";
    @Autowired
    private RuntimeService runtimeService;

    @KafkaListener("data-load.csv.outbound")
    public void processAsyncMessages(
            @Payload AsyncDataLoadResponse message,
            MessageHeaders headers) {
        AsyncDataLoadResult payload = message.geyPayload();

        RequestContext requestContext = message.getRequestContext();
        Result result = new Result(message.getStatus(), message.getDetails());
        runtimeService.createMessageCorrelation(payload.getEntityName() + ACTION + message.getStatus())
          .processInstanceId(requestContext.getProcessInstanceId())
          .setVariable(payload.getResultVariable(), result)
          .correlate();
    }

}
----

== Високорівневий план розробки

=== Технічні експертизи

* BE
* FE

=== План розробки

* Створення нової форми для завантаження даних з CSV файлів
* Розширення бібліотека Liquibase додатковими тегами.
* Розробка нового делегату для відправки асинхронних повідомлень.
* Розширення сервісу асинхронного управління даними реєстру для роботи з повідомленнями про завантаження даних.
* Розширення сервісу виконання бізнес-процесів компонентою для обробки вхідних повідомлень.
* Розробка реферетного прикладу БП.
* Зміна існуючої форми в частині необхідності вказання сутності для валідації (поле стає не обовʼязковим і валідація здійснюється тільки при наявності значення в цьому полі)
* Розширення можливості збереження файлів CSV як файлів в сервісах управління даними реєстру