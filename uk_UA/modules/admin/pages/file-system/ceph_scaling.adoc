= Масштабування розміру файлової системи Ceph
:toc-title: ЗМІСТ
:toc: auto
:toclevels: 5
:experimental:
:important-caption:     ВАЖЛИВО
:note-caption:          ПРИМІТКА
:tip-caption:           ПІДКАЗКА
:warning-caption:       ПОПЕРЕДЖЕННЯ
:caution-caption:       УВАГА
:example-caption:           Приклад
:figure-caption:            Зображення
:table-caption:             Таблиця
:appendix-caption:          Додаток
:sectnums:
:sectnumlevels: 5
:sectanchors:
:sectlinks:
:partnums:

== Проблематика та загальні практики

Розробники Ceph-платформи https://docs.ceph.com/en/latest/rados/configuration/mon-config-ref/#storage-capacity[рекомендують] завчасно реагувати на зростання розміру файлової системи та не допускати переповнення дисків. Тому
може виникнути типова потреба у масштабуванні розміру файлової системи.

WARNING: Рекомендується регулярно перевіряти місткість кластера, щоб побачити, чи досягає він верхньої межі місткості пам’яті. Коли кластер досягає свого майже повного співвідношення, додайте одне або кілька OSD, щоб збільшити місткість Ceph-кластера.

== Принцип масштабування розміру файлової системи Ceph
На Платформі реєстрів масштабування Ceph відбувається виключно засобами платформи OKD та вбудованого Ceph-оператора реалізовуючи оператор паттерн.

NOTE: Оператор паттерн — це підхід використання програмних розширень Платформи OKD, які використовують спеціальні ресурси для керування програмами, їхніми компонентами та конфігураціює. Оператори дотримуються принципів Kubernetes, зокрема циклу керування та автоматизації.

NOTE: Реконсиляція (англ. Reconcilation) або приведення в узгоджений стан — є частиною здібностей самовідновлення OKD Платформи та є процесом приведення поточного стану конфігурації в бажаний стан.

Розширення розміру файлової системи Ceph може бути виконано у два різні способи:

=== Додаванням дисків до наявних віртуальних машин

Для створення нових дисків у віртуальних машин та додавання їх у пул Ceph потрібно виконати наступні дії:

. Відкрити OKD Management Console.
. Перейти до розділу *Storage* > *Overview* > *OpenShift Container Storage* > *All instances* -> *ocs-storagecluster*.
. Натиснути `Actions` та оберіть `Add Capacity`. Наприклад:
+
image::scaling/ceph/ceph-example-5.png[ceph-example,float="center",align="center"]

. У вікні натиснути на `Add` та почекати, поки нові диски створяться та Ceph підтягне їх собі в пул
+
image::scaling/ceph/ceph-example-6.png[alt=ceph-example,width=350,height=480,ceph-example,float="center",align="center"]

NOTE: Перевірити статус новостворених OSD можна командою у поді ceph-operator: `ceph  --conf=/var/lib/rook/openshift-storage/openshift-storage.config osd tree`

NOTE: Можна запустити кілька OSD на одній віртуальній машині, але требі переконатися, що загальна пропускна здатність дисків OSD не перевищує пропускну здатність мережі, необхідну для обслуговування процесі читання або запису даних на ці диски.


=== Додавання нових віртуальних машин у Ceph MachineSet
Для додавання нових віртуальних машин в Ceph MachineSet потрібно виконати наступні дії.

. Відкрити OKD Management Console та у розділі `Compute -> MachineSets`
+
image::scaling/ceph/ceph-example-1.png[alt=ceph-example,width=200,height=480,ceph-example,float="center",align="center"]
+
знайти потрібний MachineSet. Наприклад:
+
image::scaling/ceph/ceph-example-2.png[ceph-example,float="center",align="center"]

. Натиснути на додаткове меню та обрати `Edit Machine Count`
+
image::scaling/ceph/ceph-example-3.png[ceph-example,float="center",align="center"]

. Змінити на бажану кількість
+
image::scaling/ceph/ceph-example-4.png[alt=ceph-example,width=350,height=480,ceph-example,float="center",align="center"]

. Почекати поки нова віртуальна машина буде в статусі `Running`. Після цього вона вже буде доступна для використання її Ceph та
додавання на неї нових дисків та OSD.


WARNING: Після виконання всіх кроків треба перевірити поточний статус Ceph або в OKD Management Console, або командою в ceph-operator поді ceph --conf=/var/lib/rook/openshift-storage/openshift-storage.config health detail

== Принцип масштабування розміру Ceph-бакетів
Кожний Ceph-бакет (bucket) динамічно розширяється при додаванні файлів та може досягнути розміру всього доступного місця у CephFS.
Для масштабування треба виконати кроки, які розписані вище.

== Зміна репліка-фактора для Ceph
Щоб змінити репліка-фактор на вже розгорнутому кластері OKD, потрібно виконати наступні кроки:

. Відкрити в OKD Management Console файл _.yaml_ з описом ресурсу `StorageCluster`, та змінити наступну секцію:
+
----
managedResources:
    cephBlockPools: {}
----
+
на
+
----
managedResources:
    cephBlockPools:
      reconcileStrategy: init
----

. Відкрити в OKD Management Console файл _.yaml_ з описом ресурсу `CephBlockPool`, та змінити репліка-фактор у полі `replicated -> size`:
+
----
spec:
  enableRBDStats: true
  failureDomain: rack
  replicated:
    replicasPerFailureDomain: 1
    size: 3
    targetSizeRatio: 0.49
----

. Дочекатись, доки Ceph застосує зміни.